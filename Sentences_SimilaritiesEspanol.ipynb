{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentences_SimilaritiesEspanol.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dqo5J6ZteKlA6ehv70-xUdOPMZ-3VEoi",
      "authorship_tag": "ABX9TyM1EqBdXnbIfVtleZ7Vk8T+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xanasa14/MLImplementations/blob/master/Sentences_SimilaritiesEspanol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIJVEaYTADcd",
        "outputId": "53df335f-bbe1-44e8-80d8-0626f0b5056b"
      },
      "source": [
        "!pip install --upgrade gensim\r\n",
        "!pip install -U pip setuptools wheel\r\n",
        "#pip install -U spacy\r\n",
        "\r\n",
        "!python -m spacy download es_core_news_sm\r\n",
        "!spacy download es_core_news_sm\r\n",
        "#!python -m spacy download es_core_news_md\r\n",
        "#!spacy download es_core_news_md\r\n",
        "from gensim.models import Word2Vec\r\n",
        "from gensim.models.keyedvectors import KeyedVectors\r\n",
        "import spacy\r\n",
        "print(spacy.__version__)\r\n",
        "\r\n",
        "nlp = spacy.load('es_core_news_sm')\r\n",
        " \r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.8.3)\n",
            "Collecting gensim\n",
            "  Using cached gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
            "  Using cached gensim-3.8.2-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (21.0)\n",
            "Collecting pip\n",
            "  Using cached pip-21.0-py3-none-any.whl (1.5 MB)\n",
            "  Using cached pip-20.3.4-py2.py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (52.0.0)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-52.0.0-py3-none-any.whl (784 kB)\n",
            "  Using cached setuptools-51.3.3-py3-none-any.whl (786 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (0.36.2)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
            "  Using cached wheel-0.36.1-py2.py3-none-any.whl (34 kB)\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (52.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (52.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.12.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ILEqy3AJqu"
      },
      "source": [
        "\r\n",
        "modelo = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/GensimSpanish/sbw_vectors.bin\", binary=True)\r\n",
        "#modelo = Word2Vec(frases,min_count=1)\r\n",
        "\r\n",
        "news_headlines= []\r\n",
        "\r\n",
        "\r\n",
        "news_headline0 = \"Te gustan las empanadas?\"\r\n",
        "news_headline1 = \"Te gustaron las empanadas?\"\r\n",
        "news_headline2 = \"Sopa de pollo es lo mejor que hay\"\r\n",
        "news_headline3 = \"habéis comido las empanadas?\"\r\n",
        "news_headline4 = \"habéis degustado de las empanadas?\"\r\n",
        "news_headline5 = \"Tengo que estudiar mucho para el examen que me agrada\"\r\n",
        "\r\n",
        "news_headlines_withoutLemma = [news_headline0 ,news_headline1,news_headline2, news_headline3,news_headline4,news_headline5]\r\n",
        "#https://unipython.com/curso-de-procesamiento-de-textos-gensim/"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prTMC1JuBY6a",
        "outputId": "1ab56beb-eb8b-4802-a501-9fa9e813dc2f"
      },
      "source": [
        "# Python program to remove punctuation from a given string \r\n",
        "# Function to remove punctuation \r\n",
        "def Punctuation(string): \r\n",
        "    string= string.replace(\"-PRON-\",\"\")      \r\n",
        "  \r\n",
        "    # punctuation marks \r\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~-'''\r\n",
        "  \r\n",
        "    # traverse the given string and if any punctuation \r\n",
        "    # marks occur replace it with null \r\n",
        "    for x in string.lower(): \r\n",
        "        if x in punctuations: \r\n",
        "            string = string.replace(x, \"\") \r\n",
        "  \r\n",
        "    # Print string without punctuation \r\n",
        "    return (string) \r\n",
        "#Lemmatizing from beginning \r\n",
        "for headlines in news_headlines_withoutLemma:\r\n",
        "   doc = nlp(Punctuation(headlines))\r\n",
        "   line = \" \".join([token.lemma_ for token in doc])\r\n",
        "   line= line.replace(\"-PRON-\",\"\") \r\n",
        "   line= line.replace(\"  \",\" \")      \r\n",
        "     \r\n",
        "\r\n",
        "   print(line)\r\n",
        "   news_headlines.append(line)\r\n",
        "print(news_headlines)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Te gustar los empanar\n",
            "Te gustar los empanar\n",
            "Sopa de pollo ser el mejor que haber\n",
            "haber comer los empanar\n",
            "haber degustar de los empanar\n",
            "Tengo que estudiar mucho parir el examen que me agradar\n",
            "['Te gustar los empanar', 'Te gustar los empanar', 'Sopa de pollo ser el mejor que haber', 'haber comer los empanar', 'haber degustar de los empanar', 'Tengo que estudiar mucho parir el examen que me agradar']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xml13bpjEIid",
        "outputId": "a39c05f1-e4aa-49b3-c785-8a4e6254986a"
      },
      "source": [
        "headline_tokens = []\r\n",
        "for news_headline in news_headlines:\r\n",
        "    headline_tokens.append([token.text.lower() for token in nlp(news_headline) if not token.is_stop])\r\n",
        "\r\n",
        "print(headline_tokens)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['gustar', 'empanar'], ['gustar', 'empanar'], ['sopa', 'pollo'], ['comer', 'empanar'], ['degustar', 'empanar'], ['estudiar', 'parir', 'examen', 'agradar']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YWUxt2EB-Xd",
        "outputId": "a1594e1d-b480-473e-f825-1c8850bf97f0"
      },
      "source": [
        "subject_headline = news_headlines[0]\r\n",
        "subject_token = headline_tokens[0]\r\n",
        "\r\n",
        "print('Headline: ', subject_headline)\r\n",
        "print('=' * 50)\r\n",
        "print()\r\n",
        "lineNumber = 0\r\n",
        "for token, headline in zip(headline_tokens, news_headlines):\r\n",
        "    print('-' * 50)\r\n",
        "    print(token)\r\n",
        "    print('Comparing to:', news_headlines_withoutLemma[lineNumber])\r\n",
        "    lineNumber += 1\r\n",
        "    distance = modelo.wmdistance(subject_token, token)\r\n",
        "    print('distance = %.4f' % distance)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headline:  Te gustar los empanar\n",
            "==================================================\n",
            "\n",
            "--------------------------------------------------\n",
            "['gustar', 'empanar']\n",
            "Comparing to: Te gustan las empanadas?\n",
            "distance = 0.0000\n",
            "--------------------------------------------------\n",
            "['gustar', 'empanar']\n",
            "Comparing to: Te gustaron las empanadas?\n",
            "distance = 0.0000\n",
            "--------------------------------------------------\n",
            "['sopa', 'pollo']\n",
            "Comparing to: Sopa de pollo es lo mejor que hay\n",
            "distance = 4.0874\n",
            "--------------------------------------------------\n",
            "['comer', 'empanar']\n",
            "Comparing to: habéis comido las empanadas?\n",
            "distance = 1.8441\n",
            "--------------------------------------------------\n",
            "['degustar', 'empanar']\n",
            "Comparing to: habéis degustado de las empanadas?\n",
            "distance = 2.3674\n",
            "--------------------------------------------------\n",
            "['estudiar', 'parir', 'examen']\n",
            "Comparing to: Tengo que estudiar mucho para el examen\n",
            "distance = 4.1222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ZC0JRyC73P",
        "outputId": "b6b227c9-c18a-4733-f190-67bbbf1b6838"
      },
      "source": [
        "sim = modelo.most_similar(positive=[\"gustar\"],topn=20)\r\n",
        "print(type(sim[0]))\r\n",
        "print(sim[0][0])\r\n",
        "print(sim)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "gustarle\n",
            "[('gustarle', 0.7000319957733154), ('gusta', 0.6803622245788574), ('encantar', 0.6588390469551086), ('guste', 0.6499766111373901), ('gustarles', 0.6456522345542908), ('aburrir', 0.6345496773719788), ('gustan', 0.6327551603317261), ('gustará', 0.6320923566818237), ('estancarme', 0.6305288076400757), ('rockanrolear', 0.6301405429840088), ('Compongo', 0.6212359070777893), ('agradar', 0.620132327079773), ('burbujita', 0.618711531162262), ('apasionar', 0.6173047423362732), ('desenamorarse', 0.6156854033470154), ('gustando', 0.6156095266342163), ('encanta', 0.6146389245986938), ('parejitos', 0.6142234206199646), ('aprendías', 0.6120374798774719), ('lograbas', 0.610855221748352)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAuVyNdaRXiM",
        "outputId": "36a452f2-9a07-411a-edf7-e889dfd5205f"
      },
      "source": [
        "#points\r\n",
        "print(news_headline0)\r\n",
        "print(news_headline4)\r\n",
        "print(headline_tokens[0])\r\n",
        "print(headline_tokens[4])\r\n",
        "def get_Gensim_Sim(sentence1, sentence2):\r\n",
        "  points = 0 \r\n",
        "  for word0 in sentence1:\r\n",
        "    for word1 in sentence2:\r\n",
        "      if (word0 == word1):\r\n",
        "        points +=1\r\n",
        "        break \r\n",
        "      else:\r\n",
        "        word = word0\r\n",
        "        sim = modelo.most_similar(positive=[word1],topn=30)\r\n",
        "        lemmatized = \"\" \r\n",
        "        for i in range(len(sim)):\r\n",
        "          doc = nlp(sim[i][0])\r\n",
        "          lemmatized = \" \".join([token.lemma_ for token in doc])\r\n",
        "          #print(lemmatized, sim[i][0])\r\n",
        "          if (word == lemmatized):\r\n",
        "            \r\n",
        "            print(word, lemmatized)\r\n",
        "            print(\"it is here\")\r\n",
        "            points += 0.7\r\n",
        "            break\r\n",
        "           \r\n",
        "\r\n",
        "\r\n",
        "  score = points/len(headline_tokens[0])\r\n",
        "  print(str(score * 100) + \"% similar\")\r\n",
        "\r\n",
        "\r\n",
        "get_Gensim_Sim(headline_tokens[0],headline_tokens[4])\r\n",
        "\r\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Te gustan las empanadas?\n",
            "habéis degustado de las empanadas?\n",
            "['gustar', 'empanar']\n",
            "['degustar', 'empanar']\n",
            "empanar empanar\n",
            "it is here\n",
            "85.0% similar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR0H504UW_xh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}