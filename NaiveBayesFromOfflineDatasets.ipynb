{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayesFromOfflineDatasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pyffZANmIOV64TXSsSUwGch8UzYD-3me",
      "authorship_tag": "ABX9TyOeWYQOqqsFmX6bBY8Y1AfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xanasa14/MLImplementations/blob/master/NaiveBayesFromOfflineDatasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRn3egE0WTQp",
        "outputId": "ca1a286b-6fb3-47ff-b03d-ab843b3ffa2e"
      },
      "source": [
        "import numpy as np, pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer \r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer \r\n",
        "\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "import nltk\r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "nltk.download('wordnet')\r\n",
        "from sklearn.utils.multiclass import unique_labels\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\r\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPWR6U9WjUj"
      },
      "source": [
        "#importing our cancer dataset\r\n",
        "dataset = pd.read_csv('/content/Errors.csv')\r\n",
        "#/content/fruitsBi.csv\r\n",
        "\r\n",
        "#dataset = pd.read_csv('/content/fruitsBi.csv')\r\n",
        "#X = dataset['radius mean', 'texture mean', 'perimeter mean', 'area_mean','smoothness_mean','compactness mean','concavity mean','concave points mean','symmetry mean','fractal dimension mean','radius se' ]\r\n",
        "col_list = ['id', 'label', 'Description']\r\n",
        "df = pd.read_csv(\"/content/Errors.csv\", usecols=col_list)#dataset['diagnosis']\r\n",
        "#df = pd.read_csv(\"/content/fruitsBi.csv\", usecols=col_list)#dataset['diagnosis']\r\n",
        "#Setting our X and Y for trainig and testing \r\n",
        "\r\n",
        "#Dat  = df['Description']\r\n",
        "#Y = dataset['label']\r\n",
        "#print(type(Dat))\r\n",
        "#print(Dat[0])\r\n",
        "\r\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjG6ojPhTCn9",
        "outputId": "f003540f-161d-4904-ae64-3d372daeb2c3"
      },
      "source": [
        "import spacy\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\r\n",
        "\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "#print(stopwords.words('english'))\r\n",
        "from nltk.stem import WordNetLemmatizer \r\n",
        "\r\n",
        "\r\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) \r\n",
        "import string  \r\n",
        "\r\n",
        "#Removing punctuationes and those characters\r\n",
        "def remove_punctuations(text):\r\n",
        "  for punctuation in string.punctuation:\r\n",
        "      text = text.replace(punctuation, '')\r\n",
        "  return text\r\n",
        "# Lowering Text from DataFrame\r\n",
        "def loweringText(text):\r\n",
        "    text = text.lower()\r\n",
        "    return text\r\n",
        "def convert(lst): \r\n",
        "    return ([i for item in lst for i in item.split()]) \r\n",
        "def remove_StopWords(text):\r\n",
        "  line = text.split()\r\n",
        "  text = \"\"\r\n",
        "  for word in line:\r\n",
        "    if(word not in stop_words):\r\n",
        "      text += word\r\n",
        "      text += \" \"\r\n",
        "  return text\r\n",
        "\r\n",
        "def lemmatize(text):\r\n",
        "  line = text.split()\r\n",
        "  txt = \"\"\r\n",
        "  for word in line:\r\n",
        "    doc = nlp(word)\r\n",
        "    for token in doc:\r\n",
        "      txt += token.lemma_\r\n",
        "      txt += \" \"\r\n",
        "  return txt\r\n",
        "\r\n",
        "  # Extract the lemma for each token and join\r\n",
        "  #print(line)\r\n",
        "  #> 'the strip bat be hang on -PRON- foot for good'\r\n",
        "  return line \r\n",
        "df[\"Desc\"] = df['Description'].apply(remove_punctuations).apply(loweringText).apply(remove_StopWords).apply(lemmatize)\r\n",
        "#df [\"D\"] = df[\"Desc\"].apply(lemmatize)\r\n",
        "#df.authors.apply(eval).apply(len).sum()\r\n",
        "\r\n",
        "Dat  = df['Desc']\r\n",
        "Y = dataset['label']"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_huRIgE3Jqv",
        "outputId": "d6bdcb23-5b99-45dd-8e12-d72000f3bce2"
      },
      "source": [
        "cv=CountVectorizer() \r\n",
        " \r\n",
        "# this steps generates word counts for the words in your docs \r\n",
        "word_count_vector=cv.fit_transform(Dat)\r\n",
        "word_count_vector.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zpzJ953cbF"
      },
      "source": [
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \r\n",
        "tfidf_transformer.fit(word_count_vector)\r\n",
        "# print idf values \r\n",
        "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \r\n",
        " \r\n",
        "# sort ascending \r\n",
        "df_idf.sort_values(by=['idf_weights'])\r\n",
        "\r\n",
        "#Compute the TFIDF score for your documents\r\n",
        "\r\n",
        "# count matrix \r\n",
        "count_vector=cv.transform(Dat) \r\n",
        " \r\n",
        "# tf-idf scores \r\n",
        "tf_idf_vector=tfidf_transformer.transform(count_vector)\r\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "bvugLexv4M9-",
        "outputId": "2c5f71e5-3cbf-4837-cd30-53faea7f0d6a"
      },
      "source": [
        "feature_names = cv.get_feature_names() \r\n",
        " \r\n",
        "#get tfidf vector for first document \r\n",
        "first_document_vector=tf_idf_vector[0]\r\n",
        " \r\n",
        "#print the scores \r\n",
        "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \r\n",
        "df.sort_values(by=[\"tfidf\"],ascending=False)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>froze</th>\n",
              "      <td>0.62933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>0.54952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>0.54952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anything</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wait</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tell</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>show</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>screen</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>say</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>respond</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>please</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>operator</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nothing</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>move</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>appear</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>let</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>frozen</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cursor</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>closed</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>close</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>can</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>black</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>application</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               tfidf\n",
              "froze        0.62933\n",
              "time         0.54952\n",
              "long         0.54952\n",
              "anything     0.00000\n",
              "not          0.00000\n",
              "wait         0.00000\n",
              "tell         0.00000\n",
              "show         0.00000\n",
              "screen       0.00000\n",
              "say          0.00000\n",
              "respond      0.00000\n",
              "please       0.00000\n",
              "operator     0.00000\n",
              "nothing      0.00000\n",
              "move         0.00000\n",
              "appear       0.00000\n",
              "let          0.00000\n",
              "frozen       0.00000\n",
              "cursor       0.00000\n",
              "closed       0.00000\n",
              "close        0.00000\n",
              "can          0.00000\n",
              "blue         0.00000\n",
              "black        0.00000\n",
              "application  0.00000\n",
              "window       0.00000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKS46ceu4yf1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \r\n",
        " \r\n",
        "# settings that you use for count vectorizer will go here \r\n",
        "tfidf_vectorizer=TfidfVectorizer(use_idf=True) \r\n",
        " \r\n",
        "# just send in all your docs here \r\n",
        "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(Dat)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# get the first vector out (for the first document) \r\n",
        "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0] \r\n",
        " \r\n",
        "# place tf-idf values in a pandas data frame \r\n",
        "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"]), df.sort_values(by=[\"tfidf\"],ascending=False)\r\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWXtB2Y15KYx",
        "outputId": "65d4bfac-b0b2-4abd-9cc0-f6432f365097"
      },
      "source": [
        "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\r\n",
        " \r\n",
        "# just send in all your docs here\r\n",
        "fitted_vectorizer=tfidf_vectorizer.fit(Dat)\r\n",
        "tfidf_vectorizer_vectors=fitted_vectorizer.transform(Dat)\r\n",
        "print(tfidf_vectorizer_vectors)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 23)\t0.5495196981027595\n",
            "  (0, 12)\t0.5495196981027595\n",
            "  (0, 9)\t0.6293299633690614\n",
            "  (1, 21)\t0.5971320040823352\n",
            "  (1, 20)\t0.5355994206505716\n",
            "  (1, 4)\t0.5971320040823352\n",
            "  (2, 14)\t0.4721427339470328\n",
            "  (2, 13)\t0.5263850670194029\n",
            "  (2, 8)\t0.5263850670194029\n",
            "  (2, 5)\t0.4721427339470328\n",
            "  (3, 14)\t0.5553011368955474\n",
            "  (3, 5)\t0.5553011368955474\n",
            "  (3, 0)\t0.6190971609731586\n",
            "  (4, 24)\t0.632700452304383\n",
            "  (4, 19)\t0.7743966281265882\n",
            "  (5, 24)\t0.5807663588405967\n",
            "  (5, 22)\t0.8140702896181846\n",
            "  (6, 18)\t1.0\n",
            "  (7, 14)\t0.4529941377138544\n",
            "  (7, 7)\t0.5783862720667189\n",
            "  (7, 5)\t0.4529941377138544\n",
            "  (7, 2)\t0.505036575584904\n",
            "  (8, 21)\t0.5664934727276063\n",
            "  (8, 20)\t0.5081180940243161\n",
            "  (8, 3)\t0.6487689479946717\n",
            "  (9, 23)\t0.5495196981027595\n",
            "  (9, 12)\t0.5495196981027595\n",
            "  (9, 10)\t0.6293299633690614\n",
            "  (10, 20)\t0.5081180940243161\n",
            "  (10, 4)\t0.5664934727276063\n",
            "  (10, 1)\t0.6487689479946717\n",
            "  (11, 13)\t0.7071067811865476\n",
            "  (11, 8)\t0.7071067811865476\n",
            "  (12, 11)\t0.7532548839163259\n",
            "  (12, 0)\t0.6577287281670176\n",
            "  (13, 24)\t0.4733611038942729\n",
            "  (13, 19)\t0.5793724999040357\n",
            "  (13, 16)\t0.6635184787742868\n",
            "  (14, 25)\t0.6313258812168464\n",
            "  (14, 24)\t0.45039456414519996\n",
            "  (14, 17)\t0.6313258812168464\n",
            "  (15, 18)\t0.6577287281670176\n",
            "  (15, 15)\t0.7532548839163259\n",
            "  (16, 6)\t0.7532548839163259\n",
            "  (16, 2)\t0.6577287281670176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROVGjHd6Y7Pp",
        "outputId": "96225c97-cb07-4f92-9b48-03ae9e5d484e"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Dat, Y,test_size=0.4, random_state =0  )\r\n",
        "#_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2, random_state =0  )\r\n",
        "\r\n",
        "print(\"\\nX_train:\\n\")\r\n",
        "print(X_train.head())\r\n",
        "print(X_train.shape)\r\n",
        "\r\n",
        "print(\"\\nX_test:\\n\")\r\n",
        "print(X_test.head())\r\n",
        "print(X_test.shape)\r\n",
        "\r\n",
        "print(\"\\y_train:\\n\")\r\n",
        "print(y_train.head())\r\n",
        "print(y_train.shape)\r\n",
        "\r\n",
        "print(\"\\y_test:\\n\")\r\n",
        "print(y_test.head())\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_train:\n",
            "\n",
            "14            window please wait \n",
            "10            blue screen appear \n",
            "7     application can not closed \n",
            "16             application close \n",
            "11                   cursor move \n",
            "Name: Desc, dtype: object\n",
            "(10,)\n",
            "\n",
            "X_test:\n",
            "\n",
            "1      blue screen show \n",
            "6               respond \n",
            "8     black screen show \n",
            "9      frozen long time \n",
            "13    operator say wait \n",
            "Name: Desc, dtype: object\n",
            "(7,)\n",
            "\\y_train:\n",
            "\n",
            "14    Close task in Task Manager\n",
            "10                  Reset the PC\n",
            "7     Close task in Task Manager\n",
            "16    Close task in Task Manager\n",
            "11                  Reset the PC\n",
            "Name: label, dtype: object\n",
            "(10,)\n",
            "\\y_test:\n",
            "\n",
            "1                   Reset the PC\n",
            "6     Close task in Task Manager\n",
            "8                   Reset the PC\n",
            "9                   Reset the PC\n",
            "13    Close task in Task Manager\n",
            "Name: label, dtype: object\n",
            "(7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G1mHiowa59L",
        "outputId": "9f6d0d4b-cc95-4493-a2ec-f733ea99a518"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\r\n",
        "# Train the model using the training data\r\n",
        "model.fit(X_train, y_train)\r\n",
        "# Predict the categories of the test data\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "print(y_pred)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Reset the PC' 'Close task in Task Manager' 'Reset the PC' 'Reset the PC'\n",
            " 'Close task in Task Manager' 'Close task in Task Manager' 'Reset the PC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1oZgkzbm76",
        "outputId": "dbfd964f-d501-4cbc-9a24-a75777b67798"
      },
      "source": [
        "\r\n",
        "classes = unique_labels(X_test, predicted_categories)\r\n",
        "\r\n",
        "print('classificaiton report 1\\n')\r\n",
        "print(classification_report(y_test,y_pred))\r\n",
        "print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred)))\r\n",
        "#he accuracy is 0.7738980350504514\r\n",
        "#The accuracy is 0.47058823529411764\r\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classificaiton report 1\n",
            "\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "Close task in Task Manager       1.00      1.00      1.00         3\n",
            "              Reset the PC       1.00      1.00      1.00         4\n",
            "\n",
            "                  accuracy                           1.00         7\n",
            "                 macro avg       1.00      1.00      1.00         7\n",
            "              weighted avg       1.00      1.00      1.00         7\n",
            "\n",
            "The accuracy is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J26nCKXCc712",
        "outputId": "c176d97b-a3a8-48ac-a625-07392f3e147f"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)\r\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 0],\n",
              "       [0, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vq3QxZcz6Jm"
      },
      "source": [
        ""
      ],
      "execution_count": 91,
      "outputs": []
    }
  ]
}