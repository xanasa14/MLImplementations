{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayesFromOfflineDatasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pyffZANmIOV64TXSsSUwGch8UzYD-3me",
      "authorship_tag": "ABX9TyPNUUcemYkxMNDPAt2A7CAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xanasa14/MLImplementations/blob/master/NaiveBayesFromOfflineDatasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRn3egE0WTQp",
        "outputId": "8baeb6b5-28e0-4999-f029-a65029750117"
      },
      "source": [
        "import numpy as np, pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "import nltk\r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "\r\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\r\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPWR6U9WjUj"
      },
      "source": [
        "#importing our cancer dataset\r\n",
        "#dataset = pd.read_csv('/content/Errors.csv')\r\n",
        "#/content/fruitsBi.csv\r\n",
        "\r\n",
        "dataset = pd.read_csv('/content/fruitsBi.csv')\r\n",
        "#X = dataset['radius mean', 'texture mean', 'perimeter mean', 'area_mean','smoothness_mean','compactness mean','concavity mean','concave points mean','symmetry mean','fractal dimension mean','radius se' ]\r\n",
        "col_list = ['id', 'label', 'Description']\r\n",
        "#df = pd.read_csv(\"/content/Errors.csv\", usecols=col_list)#dataset['diagnosis']\r\n",
        "df = pd.read_csv(\"/content/fruitsBi.csv\", usecols=col_list)#dataset['diagnosis']\r\n",
        "#Setting our X and Y for trainig and testing \r\n",
        "\r\n",
        "#Dat  = df['Description']\r\n",
        "#Y = dataset['label']\r\n",
        "#print(type(Dat))\r\n",
        "#print(Dat[0])\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjG6ojPhTCn9",
        "outputId": "b324f4b8-51f4-4aa5-e317-39b3b14b7beb"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\r\n",
        "\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "#print(stopwords.words('english'))\r\n",
        "from nltk.stem import WordNetLemmatizer \r\n",
        "\r\n",
        "import spacy\r\n",
        "\r\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) \r\n",
        "import string  \r\n",
        "\r\n",
        "#Removing punctuationes and those characters\r\n",
        "def remove_punctuations(text):\r\n",
        "  for punctuation in string.punctuation:\r\n",
        "      text = text.replace(punctuation, '')\r\n",
        "  return text\r\n",
        "# Lowering Text from DataFrame\r\n",
        "def loweringText(text):\r\n",
        "    text = text.lower()\r\n",
        "    return text\r\n",
        "def convert(lst): \r\n",
        "    return ([i for item in lst for i in item.split()]) \r\n",
        "def remove_StopWords(text):\r\n",
        "  line = text.split()\r\n",
        "  text = \"\"\r\n",
        "  for word in line:\r\n",
        "    if(word not in stop_words):\r\n",
        "      text += word\r\n",
        "      text += \" \"\r\n",
        "  return text\r\n",
        "\r\n",
        "def lemmatize(text):\r\n",
        "  line = text.split()\r\n",
        "  txt = \"\"\r\n",
        "  for word in line:\r\n",
        "    doc = nlp(word)\r\n",
        "    for token in doc:\r\n",
        "      txt += token.lemma_\r\n",
        "      txt += \" \"\r\n",
        "  return txt\r\n",
        "\r\n",
        "  # Extract the lemma for each token and join\r\n",
        "  #print(line)\r\n",
        "  #> 'the strip bat be hang on -PRON- foot for good'\r\n",
        "  return line \r\n",
        "df[\"Desc\"] = df['Description'].apply(remove_punctuations).apply(loweringText).apply(remove_StopWords).apply(lemmatize)\r\n",
        "#df [\"D\"] = df[\"Desc\"].apply(lemmatize)\r\n",
        "#df.authors.apply(eval).apply(len).sum()\r\n",
        "\r\n",
        "Dat  = df['Desc']\r\n",
        "Y = dataset['label']"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJiZDWV3lQDH",
        "outputId": "177a31df-de97-4296-c387-d04901246794"
      },
      "source": [
        "print(Y)\r\n",
        "print(Dat)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      apple\n",
            "1      apple\n",
            "2      apple\n",
            "3      apple\n",
            "4      apple\n",
            "5     banana\n",
            "6     banana\n",
            "7     banana\n",
            "8     banana\n",
            "9     banana\n",
            "10    banana\n",
            "11    banana\n",
            "12    banana\n",
            "13     apple\n",
            "14     apple\n",
            "15     apple\n",
            "16     apple\n",
            "17     apple\n",
            "18    banana\n",
            "19    banana\n",
            "20    banana\n",
            "21    banana\n",
            "22    banana\n",
            "23    banana\n",
            "24    banana\n",
            "25    banana\n",
            "26     apple\n",
            "27     apple\n",
            "28     apple\n",
            "29     apple\n",
            "30     apple\n",
            "Name: label, dtype: object\n",
            "0              red \n",
            "1              red \n",
            "2              red \n",
            "3              red \n",
            "4              red \n",
            "5     yellow color \n",
            "6     yellow color \n",
            "7     yellow color \n",
            "8     yellow color \n",
            "9     yellow color \n",
            "10    yellow color \n",
            "11    yellow color \n",
            "12    yellow color \n",
            "13             red \n",
            "14             red \n",
            "15             red \n",
            "16             red \n",
            "17             red \n",
            "18    yellow color \n",
            "19    yellow color \n",
            "20    yellow color \n",
            "21    yellow color \n",
            "22    yellow color \n",
            "23    yellow color \n",
            "24    yellow color \n",
            "25    yellow color \n",
            "26             red \n",
            "27             red \n",
            "28             red \n",
            "29             red \n",
            "30             red \n",
            "Name: Desc, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mqedRrAag1I"
      },
      "source": [
        "#X and y split to train and test\r\n",
        "\r\n",
        "#y = df['label']\r\n",
        "#X = df.drop('label', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iubsUXtkYpHW"
      },
      "source": [
        "#print(X)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROVGjHd6Y7Pp",
        "outputId": "8ec6b9d9-a84e-476d-c770-de70dbf28a24"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Dat, Y,test_size=0.2, random_state =0  )\r\n",
        "#_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2, random_state =0  )\r\n",
        "\r\n",
        "print(\"\\nX_train:\\n\")\r\n",
        "print(X_train.head())\r\n",
        "print(X_train.shape)\r\n",
        "\r\n",
        "print(\"\\nX_test:\\n\")\r\n",
        "print(X_test.head())\r\n",
        "print(X_test.shape)\r\n",
        "\r\n",
        "print(\"\\nX_train:\\n\")\r\n",
        "print(y_train.head())\r\n",
        "print(y_train.shape)\r\n",
        "\r\n",
        "print(\"\\nX_test:\\n\")\r\n",
        "print(y_test.head())\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_train:\n",
            "\n",
            "11    yellow color \n",
            "17             red \n",
            "23    yellow color \n",
            "5     yellow color \n",
            "16             red \n",
            "Name: Desc, dtype: object\n",
            "(24,)\n",
            "\n",
            "X_test:\n",
            "\n",
            "2              red \n",
            "29             red \n",
            "13             red \n",
            "10    yellow color \n",
            "27             red \n",
            "Name: Desc, dtype: object\n",
            "(7,)\n",
            "\n",
            "X_train:\n",
            "\n",
            "11    banana\n",
            "17     apple\n",
            "23    banana\n",
            "5     banana\n",
            "16     apple\n",
            "Name: label, dtype: object\n",
            "(24,)\n",
            "\n",
            "X_test:\n",
            "\n",
            "2      apple\n",
            "29     apple\n",
            "13     apple\n",
            "10    banana\n",
            "27     apple\n",
            "Name: label, dtype: object\n",
            "(7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G1mHiowa59L",
        "outputId": "0adac397-33cd-4a8d-946b-caa9ea8500cc"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\r\n",
        "# Train the model using the training data\r\n",
        "model.fit(X_train, y_train)\r\n",
        "# Predict the categories of the test data\r\n",
        "predicted_categories = model.predict(Y)\r\n",
        "print(predicted_categories)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKbl-nW4e56s",
        "outputId": "d4d89c24-9dd6-4d3b-c3e6-6c0755ca860c"
      },
      "source": [
        "print(predicted_categories)\r\n",
        "print(Y)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana'\n",
            " 'banana' 'banana' 'banana' 'banana' 'banana' 'banana' 'banana']\n",
            "0      apple\n",
            "1      apple\n",
            "2      apple\n",
            "3      apple\n",
            "4      apple\n",
            "5     banana\n",
            "6     banana\n",
            "7     banana\n",
            "8     banana\n",
            "9     banana\n",
            "10    banana\n",
            "11    banana\n",
            "12    banana\n",
            "13     apple\n",
            "14     apple\n",
            "15     apple\n",
            "16     apple\n",
            "17     apple\n",
            "18    banana\n",
            "19    banana\n",
            "20    banana\n",
            "21    banana\n",
            "22    banana\n",
            "23    banana\n",
            "24    banana\n",
            "25    banana\n",
            "26     apple\n",
            "27     apple\n",
            "28     apple\n",
            "29     apple\n",
            "30     apple\n",
            "Name: label, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1oZgkzbm76",
        "outputId": "51b4c6a6-2a09-454e-b6fb-7a7e025db7ab"
      },
      "source": [
        "\r\n",
        "print(\"The accuracy is {}\".format(accuracy_score(predicted_categories, Y)))\r\n",
        "#he accuracy is 0.7738980350504514\r\n",
        "#The accuracy is 0.47058823529411764\r\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is 0.5161290322580645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J26nCKXCc712",
        "outputId": "d303fff2-7bd8-4654-fa73-b8c9cc242dfd"
      },
      "source": [
        "confusion_matrix(Y, predicted_categories)\r\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 15],\n",
              "       [ 0, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMw_SS1osB1G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}