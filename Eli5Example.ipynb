{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eli5Example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOU6ibMsYvL1WAMD42iIwFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xanasa14/MLImplementations/blob/master/Eli5Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uCTwOj82P9w",
        "outputId": "74ae9db2-bee0-4412-9883-3c678fb6d8d6"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "\r\n",
        "categories = ['alt.atheism', 'soc.religion.christian',\r\n",
        "              'comp.graphics', 'sci.med']\r\n",
        "twenty_train = fetch_20newsgroups(\r\n",
        "    subset='train',\r\n",
        "    categories=categories,\r\n",
        "    shuffle=True,\r\n",
        "    random_state=42,\r\n",
        "    remove=('headers', 'footers'),\r\n",
        ")\r\n",
        "twenty_test = fetch_20newsgroups(\r\n",
        "    subset='test',\r\n",
        "    categories=categories,\r\n",
        "    shuffle=True,\r\n",
        "    random_state=42,\r\n",
        "    remove=('headers', 'footers'),\r\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WCxVb302ryH",
        "outputId": "fe6a1280-942f-4443-c535-0532084876be"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (1.0.0)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4tDjVi12TOn",
        "outputId": "0d18de4c-af0b-44d3-ff54-4e5675ac7113"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.layers import Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Bidirectional, concatenate\r\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from eli5.lime import TextExplainer\r\n",
        "import regex as re\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "class KerasTextClassifier(BaseEstimator, TransformerMixin):\r\n",
        "    '''Wrapper class for keras text classification models that takes raw text as input.'''\r\n",
        "    \r\n",
        "    def __init__(self, max_words=30000, input_length=100, emb_dim=20, n_classes=4, epochs=5, batch_size=32):\r\n",
        "        self.max_words = max_words\r\n",
        "        self.input_length = input_length\r\n",
        "        self.emb_dim = emb_dim\r\n",
        "        self.n_classes = n_classes\r\n",
        "        self.epochs = epochs\r\n",
        "        self.bs = batch_size\r\n",
        "        self.model = self._get_model()\r\n",
        "        self.tokenizer = Tokenizer(num_words=self.max_words+1,\r\n",
        "                                   lower=True, split=' ', oov_token=\"UNK\")\r\n",
        "    \r\n",
        "    def _get_model(self):\r\n",
        "        input_text = Input((self.input_length,))\r\n",
        "        text_embedding = Embedding(input_dim=self.max_words + 2, output_dim=self.emb_dim,\r\n",
        "                                   input_length=self.input_length, mask_zero=False)(input_text)\r\n",
        "        text_embedding = SpatialDropout1D(0.5)(text_embedding)\r\n",
        "        bilstm = Bidirectional(LSTM(units=32, return_sequences=True, recurrent_dropout=0.5))(text_embedding)\r\n",
        "        x = concatenate([GlobalAveragePooling1D()(bilstm), GlobalMaxPooling1D()(bilstm)])\r\n",
        "        x = Dropout(0.7)(x)\r\n",
        "        x = Dense(512, activation=\"relu\")(x)\r\n",
        "        x = Dropout(0.6)(x)\r\n",
        "        x = Dense(512, activation=\"relu\")(x)\r\n",
        "        x = Dropout(0.5)(x)\r\n",
        "        out = Dense(units=self.n_classes, activation=\"softmax\")(x)\r\n",
        "        model = Model(input_text, out)\r\n",
        "        model.compile(optimizer=\"adam\",\r\n",
        "                      loss=\"sparse_categorical_crossentropy\",\r\n",
        "                      metrics=[\"accuracy\"])\r\n",
        "        return model\r\n",
        "    \r\n",
        "    def _get_sequences(self, texts):\r\n",
        "        seqs = self.tokenizer.texts_to_sequences(texts)\r\n",
        "        return pad_sequences(seqs, maxlen=self.input_length, value=0)\r\n",
        "    \r\n",
        "    def _preprocess(self, texts):\r\n",
        "        return [re.sub(r\"\\d\", \"DIGIT\", x) for x in texts]\r\n",
        "    \r\n",
        "    def fit(self, X, y):\r\n",
        "        '''\r\n",
        "        Fit the vocabulary and the model.\r\n",
        "        \r\n",
        "        :params:\r\n",
        "        X: list of texts.\r\n",
        "        y: labels.\r\n",
        "        '''\r\n",
        "        \r\n",
        "        self.tokenizer.fit_on_texts(self._preprocess(X))\r\n",
        "        self.tokenizer.word_index = {e: i for e,i in self.tokenizer.word_index.items() if i <= self.max_words}\r\n",
        "        self.tokenizer.word_index[self.tokenizer.oov_token] = self.max_words + 1\r\n",
        "        seqs = self._get_sequences(self._preprocess(X))\r\n",
        "        self.model.fit(seqs, y, batch_size=self.bs, epochs=self.epochs, validation_split=0.1)\r\n",
        "    \r\n",
        "    def predict_proba(self, X, y=None):\r\n",
        "        seqs = self._get_sequences(self._preprocess(X))\r\n",
        "        return self.model.predict(seqs)\r\n",
        "    \r\n",
        "    def predict(self, X, y=None):\r\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\r\n",
        "    \r\n",
        "    def score(self, X, y):\r\n",
        "        y_pred = self.predict(X)\r\n",
        "        return accuracy_score(y, y_pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDDpudx2W04"
      },
      "source": [
        "text_model = KerasTextClassifier(epochs=20, max_words=20000, input_length=200)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgDDarZw_lJ1",
        "outputId": "1ec13d83-8ee7-417f-a7fe-75022905ea63"
      },
      "source": [
        "text_model.fit(twenty_train.data, twenty_train.target)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "64/64 [==============================] - 20s 255ms/step - loss: 1.3840 - accuracy: 0.2664 - val_loss: 1.3664 - val_accuracy: 0.3540\n",
            "Epoch 2/20\n",
            "64/64 [==============================] - 16s 243ms/step - loss: 1.3299 - accuracy: 0.3711 - val_loss: 1.1613 - val_accuracy: 0.4646\n",
            "Epoch 3/20\n",
            "64/64 [==============================] - 15s 235ms/step - loss: 1.0730 - accuracy: 0.5185 - val_loss: 0.7732 - val_accuracy: 0.6416\n",
            "Epoch 4/20\n",
            "64/64 [==============================] - 15s 235ms/step - loss: 0.7935 - accuracy: 0.6317 - val_loss: 0.6436 - val_accuracy: 0.7257\n",
            "Epoch 5/20\n",
            "64/64 [==============================] - 15s 237ms/step - loss: 0.5886 - accuracy: 0.7270 - val_loss: 0.5710 - val_accuracy: 0.7434\n",
            "Epoch 6/20\n",
            "64/64 [==============================] - 15s 240ms/step - loss: 0.4970 - accuracy: 0.7775 - val_loss: 0.4971 - val_accuracy: 0.8142\n",
            "Epoch 7/20\n",
            "64/64 [==============================] - 16s 243ms/step - loss: 0.4660 - accuracy: 0.8015 - val_loss: 0.5015 - val_accuracy: 0.8186\n",
            "Epoch 8/20\n",
            "64/64 [==============================] - 16s 244ms/step - loss: 0.3694 - accuracy: 0.8436 - val_loss: 0.5194 - val_accuracy: 0.8319\n",
            "Epoch 9/20\n",
            "64/64 [==============================] - 16s 242ms/step - loss: 0.3390 - accuracy: 0.8654 - val_loss: 0.6032 - val_accuracy: 0.7743\n",
            "Epoch 10/20\n",
            "64/64 [==============================] - 15s 241ms/step - loss: 0.3663 - accuracy: 0.8624 - val_loss: 0.5549 - val_accuracy: 0.8009\n",
            "Epoch 11/20\n",
            "64/64 [==============================] - 15s 241ms/step - loss: 0.2662 - accuracy: 0.9029 - val_loss: 0.4773 - val_accuracy: 0.8319\n",
            "Epoch 12/20\n",
            "64/64 [==============================] - 15s 240ms/step - loss: 0.2519 - accuracy: 0.9103 - val_loss: 0.5474 - val_accuracy: 0.8496\n",
            "Epoch 13/20\n",
            "64/64 [==============================] - 15s 238ms/step - loss: 0.2357 - accuracy: 0.9052 - val_loss: 0.5056 - val_accuracy: 0.8319\n",
            "Epoch 14/20\n",
            "64/64 [==============================] - 15s 239ms/step - loss: 0.2087 - accuracy: 0.9242 - val_loss: 0.5187 - val_accuracy: 0.8584\n",
            "Epoch 15/20\n",
            "64/64 [==============================] - 15s 240ms/step - loss: 0.1652 - accuracy: 0.9411 - val_loss: 0.5375 - val_accuracy: 0.8407\n",
            "Epoch 16/20\n",
            "36/64 [===============>..............] - ETA: 6s - loss: 0.2100 - accuracy: 0.9135"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuRHJGvk_nCy"
      },
      "source": [
        "text_model.score(twenty_test.data, twenty_test.target)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x52v6Uo_uw7"
      },
      "source": [
        "doc = twenty_test.data[2]\r\n",
        "te = TextExplainer(random_state=42)\r\n",
        "te.fit(doc, text_model.predict_proba)\r\n",
        "te.show_prediction(target_names=twenty_train.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWsB535o_xF9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}